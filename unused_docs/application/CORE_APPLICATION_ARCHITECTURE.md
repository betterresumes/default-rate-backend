# üèóÔ∏è AccuNode - Core Application Architecture

## üìã **Table of Contents**
1. [Architecture Overview](#architecture-overview)
2. [Core Components](#core-components)
3. [Data Flow Diagrams](#data-flow-diagrams)
4. [Database Design](#database-design)
5. [Access Control System](#access-control-system)
6. [ML Pipeline](#ml-pipeline)
7. [Security & Authentication](#security--authentication)

---

## üéØ **Architecture Overview**

AccuNode is a **multi-tenant ML-based Default Rate Prediction API** built with FastAPI, utilizing machine learning models to predict corporate default probabilities based on financial ratios.

### **System Architecture**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CLIENT APPLICATIONS                          ‚îÇ
‚îÇ   Web Apps ‚îÇ Mobile Apps ‚îÇ CLI Tools ‚îÇ Third-party APIs       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ HTTPS/REST API
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  APPLICATION LAYER                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ Rate Limit  ‚îÇ  ‚îÇ Auth/JWT    ‚îÇ  ‚îÇ CORS/Security‚îÇ            ‚îÇ
‚îÇ  ‚îÇ Middleware  ‚îÇ  ‚îÇ Middleware  ‚îÇ  ‚îÇ Headers      ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ Predictions ‚îÇ  ‚îÇ Companies   ‚îÇ  ‚îÇ Auth & User ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ API         ‚îÇ  ‚îÇ API         ‚îÇ  ‚îÇ Management  ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   SERVICE LAYER                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇML Prediction‚îÇ  ‚îÇCompany      ‚îÇ  ‚îÇBulk Upload  ‚îÇ            ‚îÇ
‚îÇ  ‚îÇService      ‚îÇ  ‚îÇService      ‚îÇ  ‚îÇService      ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DATA LAYER                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇPostgreSQL   ‚îÇ  ‚îÇRedis Cache  ‚îÇ  ‚îÇML Models    ‚îÇ            ‚îÇ
‚îÇ  ‚îÇDatabase     ‚îÇ  ‚îÇ& Sessions   ‚îÇ  ‚îÇ(.pkl files) ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **Technology Stack**

| Layer | Technology | Purpose |
|-------|------------|---------|
| **API Framework** | FastAPI 0.104+ | High-performance async REST API |
| **Database** | PostgreSQL 15+ | Primary data storage with ACID compliance |
| **Cache** | Redis 7+ | Session management, rate limiting, caching |
| **ML Framework** | Scikit-learn, LightGBM | Pre-trained models for predictions |
| **Authentication** | JWT (JSON Web Tokens) | Stateless authentication & authorization |
| **Validation** | Pydantic | Request/response data validation |
| **ORM** | SQLAlchemy 2.0+ | Database abstraction and relationships |
| **Async Processing** | Celery + Redis | Background job processing |

---

## üß© **Core Components**

### **1. Multi-Tenant Authentication System**

#### **User Role Hierarchy** (5 Levels)
```python
class UserRole(str, Enum):
    SUPER_ADMIN = "super_admin"      # Platform-wide access
    TENANT_ADMIN = "tenant_admin"    # Cross-organization access  
    ORG_ADMIN = "org_admin"          # Organization admin
    ORG_MEMBER = "org_member"        # Organization member
    USER = "user"                    # Basic authenticated user
```

#### **Access Control Flow**
```
Registration ‚Üí Email Verification ‚Üí Role Assignment ‚Üí Organization Joining
     ‚îÇ              ‚îÇ                    ‚îÇ                    ‚îÇ
     ‚ñº              ‚ñº                    ‚ñº                    ‚ñº
[pending] ‚Üí [verified] ‚Üí [role_assigned] ‚Üí [active_in_org]
```

### **2. Data Access Levels** (3-Tier System)

```python
class AccessLevel(str, Enum):
    PERSONAL = "personal"        # User's own data
    ORGANIZATION = "organization" # Organization shared data  
    SYSTEM = "system"            # Platform-wide public data
```

#### **Data Visibility Matrix**
| User Role | Personal Data | Org Data | System Data | Cross-Org Data |
|-----------|---------------|----------|-------------|----------------|
| `super_admin` | ‚úÖ All | ‚úÖ All | ‚úÖ All | ‚úÖ All |
| `tenant_admin` | ‚úÖ Own | ‚úÖ All Orgs | ‚úÖ All | ‚úÖ All |
| `org_admin` | ‚úÖ Own | ‚úÖ Own Org | ‚úÖ All | ‚ùå |
| `org_member` | ‚úÖ Own | ‚úÖ Own Org | ‚úÖ All | ‚ùå |
| `user` | ‚úÖ Own | ‚ùå | ‚úÖ All | ‚ùå |

### **3. Prediction Engine Architecture**

```
Financial Data Input ‚Üí Validation ‚Üí ML Processing ‚Üí Risk Assessment ‚Üí Storage
        ‚îÇ                 ‚îÇ            ‚îÇ              ‚îÇ             ‚îÇ
        ‚ñº                 ‚ñº            ‚ñº              ‚ñº             ‚ñº
   [5 Ratios]     [Schema Check]  [2 Models]   [Risk Levels]   [Database]
```

#### **Annual Prediction Pipeline**
```python
# Input: 5 Financial Ratios
{
    "long_term_debt_to_total_capital": float,  # Leverage ratio
    "total_debt_to_ebitda": float,            # Debt coverage
    "net_income_margin": float,               # Profitability
    "ebit_to_interest_expense": float,        # Interest coverage
    "return_on_assets": float                 # Asset efficiency
}

# ML Models: Ensemble Approach
‚îú‚îÄ‚îÄ Logistic Regression Model
‚îî‚îÄ‚îÄ Step Function Model

# Output: Risk Assessment
{
    "probability": float,           # Default probability (0-1)
    "risk_level": str,             # "Low"|"Medium"|"High"  
    "confidence": float,           # Model confidence (0-1)
    "predicted_at": datetime       # Prediction timestamp
}
```

#### **Quarterly Prediction Pipeline**
```python
# Input: 6 Financial Ratios  
{
    "current_ratio": float,                   # Liquidity
    "quick_ratio": float,                     # Immediate liquidity
    "debt_to_equity": float,                  # Capital structure
    "inventory_turnover": float,              # Operational efficiency
    "receivables_turnover": float,            # Collection efficiency
    "working_capital_to_total_assets": float  # Working capital management
}

# ML Models: Advanced Ensemble
‚îú‚îÄ‚îÄ Logistic Regression Model
‚îú‚îÄ‚îÄ LightGBM Model  
‚îî‚îÄ‚îÄ Step Function Model

# Output: Enhanced Risk Assessment
{
    "logistic_probability": float,    # Logistic model result
    "gbm_probability": float,         # LightGBM model result
    "ensemble_probability": float,    # Combined result
    "risk_level": str,               # Risk classification
    "confidence": float,             # Prediction confidence
    "predicted_at": datetime         # Timestamp
}
```

---

## üìä **Data Flow Diagrams**

### **1. User Registration & Authentication Flow**
```mermaid
graph TD
    A[User Registration] --> B{Email Validation}
    B -->|Valid| C[Send Verification Email]
    B -->|Invalid| D[Return Error]
    C --> E[User Clicks Verification Link]
    E --> F{Token Valid?}
    F -->|Yes| G[Activate Account]
    F -->|No| H[Show Error]
    G --> I[User Can Login]
    I --> J[Generate JWT Token]
    J --> K[Access Protected Resources]
    
    style A fill:#e1f5fe
    style G fill:#c8e6c9
    style D fill:#ffcdd2
    style H fill:#ffcdd2
```

### **2. Prediction Creation Flow**
```mermaid
graph TD
    A[API Request] --> B{Authentication}
    B -->|Valid JWT| C[Extract User Context]
    B -->|Invalid| D[Return 401 Error]
    
    C --> E{Validate Financial Data}
    E -->|Valid| F[Determine Access Level]
    E -->|Invalid| G[Return 400 Error]
    
    F --> H[Create/Find Company]
    H --> I[Check Duplicate Prediction]
    I -->|New| J[Run ML Models]
    I -->|Duplicate| K[Return Conflict Error]
    
    J --> L[Store Prediction]
    L --> M[Return Success Response]
    
    style A fill:#e1f5fe
    style M fill:#c8e6c9
    style D fill:#ffcdd2
    style G fill:#ffcdd2
    style K fill:#fff3e0
```

### **3. Bulk Upload Processing Flow**
```mermaid
graph TD
    A[Upload CSV File] --> B{File Validation}
    B -->|Valid| C[Create Bulk Job]
    B -->|Invalid| D[Return Error]
    
    C --> E[Queue Background Task]
    E --> F[Process Each Row]
    F --> G{Row Valid?}
    G -->|Yes| H[Create Prediction]
    G -->|No| I[Log Error]
    
    H --> J[Increment Success Count]
    I --> K[Increment Error Count]
    
    J --> L{More Rows?}
    K --> L
    L -->|Yes| F
    L -->|No| M[Update Job Status]
    M --> N[Send Completion Notification]
    
    style A fill:#e1f5fe
    style N fill:#c8e6c9
    style D fill:#ffcdd2
```

---

## üóÑÔ∏è **Database Design**

### **Core Entity Relationships**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Users       ‚îÇ    ‚îÇ Organizations   ‚îÇ    ‚îÇ   Companies     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ id (UUID)       ‚îÇ    ‚îÇ id (UUID)       ‚îÇ    ‚îÇ id (UUID)       ‚îÇ
‚îÇ email           ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ name            ‚îÇ    ‚îÇ symbol          ‚îÇ
‚îÇ role            ‚îÇ    ‚îÇ domain          ‚îÇ    ‚îÇ name            ‚îÇ
‚îÇ organization_id ‚îÇ    ‚îÇ created_at      ‚îÇ    ‚îÇ sector          ‚îÇ
‚îÇ created_at      ‚îÇ    ‚îÇ updated_at      ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ market_cap      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ organization_id ‚îÇ
                                              ‚îÇ access_level    ‚îÇ
                                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                       ‚îÇ
                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                              ‚ñº                                                 ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇAnnualPredictions‚îÇ                              ‚îÇQuarterlyPredicts‚îÇ
                    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                              ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                    ‚îÇ id (UUID)       ‚îÇ                              ‚îÇ id (UUID)       ‚îÇ
                    ‚îÇ company_id      ‚îÇ                              ‚îÇ company_id      ‚îÇ
                    ‚îÇ organization_id ‚îÇ                              ‚îÇ organization_id ‚îÇ
                    ‚îÇ reporting_year  ‚îÇ                              ‚îÇ reporting_year  ‚îÇ
                    ‚îÇ probability     ‚îÇ                              ‚îÇ reporting_quarter‚îÇ
                    ‚îÇ risk_level      ‚îÇ                              ‚îÇ ensemble_prob   ‚îÇ
                    ‚îÇ confidence      ‚îÇ                              ‚îÇ logistic_prob   ‚îÇ
                    ‚îÇ access_level    ‚îÇ                              ‚îÇ gbm_probability ‚îÇ
                    ‚îÇ created_by      ‚îÇ                              ‚îÇ risk_level      ‚îÇ
                    ‚îÇ [5 ratios]      ‚îÇ                              ‚îÇ [6 ratios]      ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **Key Database Constraints**

#### **Unique Constraints**
```sql
-- Prevent duplicate predictions
UNIQUE(company_id, reporting_year, organization_id) -- Annual
UNIQUE(company_id, reporting_year, reporting_quarter, organization_id) -- Quarterly

-- Ensure unique user emails  
UNIQUE(email)

-- Company symbol uniqueness per organization
UNIQUE(symbol, organization_id)
```

#### **Foreign Key Relationships**
```sql
-- User belongs to organization
users.organization_id ‚Üí organizations.id

-- Predictions belong to company and user
predictions.company_id ‚Üí companies.id
predictions.created_by ‚Üí users.id
predictions.organization_id ‚Üí organizations.id

-- Companies can belong to organizations  
companies.organization_id ‚Üí organizations.id
```

### **Indexing Strategy**
```sql
-- Performance optimization indexes
CREATE INDEX idx_predictions_created_at ON annual_predictions(created_at);
CREATE INDEX idx_predictions_company_year ON annual_predictions(company_id, reporting_year);
CREATE INDEX idx_predictions_access_level ON annual_predictions(access_level);
CREATE INDEX idx_predictions_organization ON annual_predictions(organization_id);
CREATE INDEX idx_companies_symbol ON companies(symbol);
CREATE INDEX idx_companies_sector ON companies(sector);
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_organization ON users(organization_id);
```

---

## üîê **Access Control System**

### **Authentication Flow**
```python
# 1. JWT Token Generation
def create_access_token(data: dict, expires_delta: timedelta = None):
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

# 2. Token Validation
async def get_current_user(token: str = Depends(oauth2_scheme)):
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        username: str = payload.get("sub")
        if username is None:
            raise credentials_exception
    except JWTError:
        raise credentials_exception
    
    user = get_user(db, username=username)
    if user is None:
        raise credentials_exception
    return user
```

### **Authorization Levels**

#### **Data Access Rules**
```python
def get_data_access_filter(user: User, prediction_model, include_system: bool = False):
    """Generate SQL filter based on user access permissions"""
    
    if user.role == "super_admin":
        return None  # No filter - access all data
    
    elif user.role == "tenant_admin":
        return None  # No filter - cross-organization access
    
    elif user.organization_id:  # org_admin or org_member
        filters = [
            prediction_model.created_by == str(user.id),  # Own data
            prediction_model.organization_id == user.organization_id  # Org data
        ]
        if include_system:
            filters.append(prediction_model.access_level == "system")
        return or_(*filters)
    
    else:  # user role
        filters = [prediction_model.created_by == str(user.id)]  # Only own data
        if include_system:
            filters.append(prediction_model.access_level == "system")
        return or_(*filters)
```

#### **Resource Permission Matrix**

| Resource | Create | Read | Update | Delete | Bulk Operations |
|----------|--------|------|--------|--------|-----------------|
| **Own Predictions** | ‚úÖ All Roles | ‚úÖ All Roles | ‚úÖ Creator Only | ‚úÖ Creator Only | ‚úÖ All Roles |
| **Org Predictions** | ‚úÖ Org Members+ | ‚úÖ Org Members+ | ‚úÖ Org Admin+ | ‚úÖ Org Admin+ | ‚úÖ Org Admin+ |
| **System Predictions** | ‚úÖ Super Admin | ‚úÖ All Roles | ‚úÖ Super Admin | ‚úÖ Super Admin | ‚úÖ Super Admin |
| **User Management** | ‚ùå | ‚úÖ Self + Admin | ‚úÖ Self + Admin | ‚úÖ Admin Only | ‚úÖ Admin Only |
| **Organization Management** | ‚úÖ Tenant Admin+ | ‚úÖ Members+ | ‚úÖ Org Admin+ | ‚úÖ Tenant Admin+ | ‚úÖ Tenant Admin+ |

---

## ü§ñ **ML Pipeline**

### **Model Architecture**

#### **Annual Prediction Models**
```python
# Model Files Location: /app/models/
‚îú‚îÄ‚îÄ annual_logistic_model.pkl    # Logistic Regression (primary)
‚îú‚îÄ‚îÄ annual_step.pkl              # Step Function (secondary) 
‚îî‚îÄ‚îÄ scoring_info.pkl             # Feature scaling parameters

# Ensemble Logic
def predict_annual(financial_data: dict) -> dict:
    # 1. Data preprocessing & scaling
    scaled_features = scaler.transform(financial_ratios)
    
    # 2. Run both models
    logistic_prob = logistic_model.predict_proba(scaled_features)[0][1]
    step_prob = step_model.predict_proba(scaled_features)[0][1]
    
    # 3. Ensemble combination (weighted average)
    final_probability = (logistic_prob * 0.7) + (step_prob * 0.3)
    
    # 4. Risk categorization
    risk_level = categorize_risk(final_probability)
    confidence = calculate_confidence(logistic_prob, step_prob)
    
    return {
        "probability": final_probability,
        "risk_level": risk_level,
        "confidence": confidence
    }
```

#### **Quarterly Prediction Models**  
```python
# Model Files Location: /app/models/
‚îú‚îÄ‚îÄ quarterly_lgb_model.pkl       # LightGBM (primary)
‚îú‚îÄ‚îÄ quarterly_logistic_model.pkl  # Logistic Regression (secondary)
‚îú‚îÄ‚îÄ quarterly_step.pkl            # Step Function (tertiary)
‚îî‚îÄ‚îÄ quarterly_scoring_info.pkl    # Feature scaling parameters

# Advanced Ensemble Logic
def predict_quarterly(financial_data: dict) -> dict:
    # 1. Feature engineering & scaling
    scaled_features = quarterly_scaler.transform(financial_ratios)
    
    # 2. Run all three models
    lgb_prob = lgb_model.predict(scaled_features)[0]
    logistic_prob = logistic_model.predict_proba(scaled_features)[0][1] 
    step_prob = step_model.predict_proba(scaled_features)[0][1]
    
    # 3. Weighted ensemble (LightGBM has highest weight)
    ensemble_prob = (lgb_prob * 0.5) + (logistic_prob * 0.3) + (step_prob * 0.2)
    
    # 4. Risk assessment with enhanced confidence
    risk_level = categorize_risk_quarterly(ensemble_prob)
    confidence = calculate_ensemble_confidence(lgb_prob, logistic_prob, step_prob)
    
    return {
        "logistic_probability": logistic_prob,
        "gbm_probability": lgb_prob, 
        "ensemble_probability": ensemble_prob,
        "risk_level": risk_level,
        "confidence": confidence
    }
```

### **Risk Classification System**
```python
def categorize_risk(probability: float) -> str:
    """Convert probability to risk level"""
    if probability < 0.3:
        return "Low"      # < 30% default probability
    elif probability < 0.7:
        return "Medium"   # 30-70% default probability  
    else:
        return "High"     # > 70% default probability

def calculate_confidence(prob1: float, prob2: float) -> float:
    """Calculate model confidence based on agreement"""
    agreement = 1.0 - abs(prob1 - prob2)  # Higher agreement = higher confidence
    return min(max(agreement, 0.0), 1.0)   # Bound between 0-1
```

---

## üõ°Ô∏è **Security & Authentication**

### **Security Layers**

#### **1. Input Validation & Sanitization**
```python
# Pydantic Models for Request Validation
class AnnualPredictionRequest(BaseModel):
    company_symbol: str = Field(..., min_length=1, max_length=10)
    company_name: str = Field(..., min_length=1, max_length=200)
    market_cap: float = Field(..., gt=0)
    sector: str = Field(..., min_length=1, max_length=100)
    reporting_year: str = Field(..., regex=r'^\d{4}$')
    
    # Financial ratios with realistic bounds
    long_term_debt_to_total_capital: float = Field(..., ge=0, le=2.0)
    total_debt_to_ebitda: float = Field(..., ge=0, le=50.0)
    net_income_margin: float = Field(..., ge=-1.0, le=1.0)
    ebit_to_interest_expense: float = Field(..., ge=0, le=100.0)
    return_on_assets: float = Field(..., ge=-1.0, le=1.0)

# SQL Injection Prevention (SQLAlchemy ORM)
# All queries use parameterized statements automatically
```

#### **2. Rate Limiting Strategy**
```python
# Rate limits per endpoint type
RATE_LIMITS = {
    "ml_predictions": "10/minute",      # ML inference endpoints
    "data_read": "100/minute",          # Data retrieval endpoints
    "upload": "5/minute",               # File upload endpoints
    "auth": "20/minute",                # Authentication endpoints
    "analytics": "50/minute"            # Statistics/dashboard endpoints
}

# Implementation using Redis-backed sliding window
@rate_limit_ml
async def create_prediction(request: Request, ...):
    # Rate limiting automatically applied
    pass
```

#### **3. Data Encryption**
```python
# At Rest: Database-level encryption
DATABASE_URL = "postgresql://user:pass@encrypted-rds-endpoint/db"

# In Transit: HTTPS/TLS 1.2+
app.add_middleware(HTTPSRedirectMiddleware)

# Secrets Management: AWS Parameter Store
async def get_secret(parameter_name: str):
    ssm = boto3.client('ssm')
    response = ssm.get_parameter(
        Name=parameter_name,
        WithDecryption=True
    )
    return response['Parameter']['Value']
```

#### **4. Security Headers**
```python
# Security middleware configuration
@app.middleware("http")
async def add_security_headers(request: Request, call_next):
    response = await call_next(request)
    
    # Security headers
    response.headers["X-Content-Type-Options"] = "nosniff"
    response.headers["X-Frame-Options"] = "DENY" 
    response.headers["X-XSS-Protection"] = "1; mode=block"
    response.headers["Strict-Transport-Security"] = "max-age=31536000; includeSubDomains"
    response.headers["Content-Security-Policy"] = "default-src 'self'"
    
    return response
```

### **Audit & Logging**
```python
# Comprehensive logging for security events
logger.info(f"User {user.email} created prediction {prediction.id}")
logger.warning(f"Failed login attempt for {email} from IP {client_ip}")
logger.error(f"Unauthorized access attempt to {endpoint} by user {user.id}")

# Database audit trails
class BaseModel(SQLAlchemyBase):
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    created_by = Column(String, nullable=True)  # Track who created each record
```

---

## üìà **Performance Optimization**

### **Caching Strategy**
```python
# Redis caching for frequently accessed data
@cache_result(ttl=3600)  # 1 hour cache
async def get_company_predictions(company_id: str):
    # Expensive database query cached
    pass

# Database query optimization
def get_predictions_optimized(user_id: str, page: int = 1):
    return db.query(Prediction)\
        .options(joinedload(Prediction.company))\  # Eager loading
        .filter(Prediction.created_by == user_id)\
        .offset((page-1) * PAGE_SIZE)\
        .limit(PAGE_SIZE)\
        .all()
```

### **Async Processing**
```python
# Background job processing with Celery
@celery_app.task
def process_bulk_upload(file_data: bytes, user_id: str):
    # Long-running bulk operations moved to background
    df = pd.read_csv(io.StringIO(file_data.decode()))
    
    for index, row in df.iterrows():
        # Process each prediction asynchronously
        create_prediction_from_row.delay(row.to_dict(), user_id)
```

This completes the **Core Application Architecture** documentation. Would you like me to continue with the next documentation section? I can proceed with:

2. **Detailed API Documentation**
3. **AWS Infrastructure Guide** 
4. **Local Development Setup**
5. **Production Deployment Guide**

Which section would you like me to work on next?
